{"cells":[{"metadata":{},"cell_type":"markdown","source":"# XGBoost with Scikit-Learn Pipeline & GridSearchCV\n\nXGBoost provides a wrapper interface to use the model as if it another model from Scikit-Learn [(more info in the documentation)](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn). \n\nIn this notebook we show an example on how we can use XGBoost with Pipelines and GridSearchCV like any other Scikit-Learn model."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset\n\nFor this example we'll use a simple dataset: [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\nX = df.drop(columns=[\"id\", \"Unnamed: 32\", \"diagnosis\"])\ny = df[\"diagnosis\"].map({'B': 0, 'M': 1})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define the Pipeline and GridSearch\n\nThe `XGBClassifier` class implements the Scikit-Learn interface for using XGBoost for classification. That means that it has the familiar `fit` method as well as `predict`, `score` and so on.\n\nThe preprocessing methods to use in the pipeline and the parameters to optimize are just for the sake of the example."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBClassifier()\n\npipeline = Pipeline([\n    ('standard_scaler', StandardScaler()), \n    ('pca', PCA()), \n    ('model', model)\n])\n\nparam_grid = {\n    'pca__n_components': [5, 10, 15, 20, 25, 30],\n    'model__max_depth': [2, 3, 5, 7, 10],\n    'model__n_estimators': [10, 100, 500],\n}\n\ngrid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\n\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CV results\n\nHere are the results of the model that gave the best mean score in the k-fold cross-validation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"mean_score = grid.cv_results_[\"mean_test_score\"][grid.best_index_]\nstd_score = grid.cv_results_[\"std_test_score\"][grid.best_index_]\n\ngrid.best_params_, mean_score, std_score\n\nprint(f\"Best parameters: {grid.best_params_}\")\nprint(f\"Mean CV score: {mean_score: .6f}\")\nprint(f\"Standard deviation of CV score: {std_score: .6f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feel free to ask anything or correct me if I made some mistake.\n\nHope this was helpful, have a nice day ðŸ™‚"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}