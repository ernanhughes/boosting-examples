{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# XGBoost for Churn prediction with the Telco dataset\n\n### This code was taken from [this webinar](https://www.youtube.com/watch?v=GrJP9FLV3FE)\n\nThis notebook contains:\n\n* Data pre-processing\n* Handling missing values and column names (for drawing the tree)\n* Modeling a XGBoost\n* GridSearchCV for parameter tuning","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, plot_confusion_matrix\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-14T01:28:38.251125Z","iopub.execute_input":"2021-09-14T01:28:38.251567Z","iopub.status.idle":"2021-09-14T01:28:39.327847Z","shell.execute_reply.started":"2021-09-14T01:28:38.251482Z","shell.execute_reply":"2021-09-14T01:28:39.327087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Loading the data\nraw_data = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\nraw_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.329292Z","iopub.execute_input":"2021-09-14T01:28:39.329783Z","iopub.status.idle":"2021-09-14T01:28:39.427745Z","shell.execute_reply.started":"2021-09-14T01:28:39.329751Z","shell.execute_reply":"2021-09-14T01:28:39.42703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset is a bit different from the one used in the webinar. On the original dataset, there were 33 columns, and some of them had to be deleted. This one seems to be somewhat cleaned. Some of the columns that he used for the model are missing. We could still drop the Customer ID column.\n\nBut, for the sake of the example, we will check the values in each column so that everything is okay.","metadata":{}},{"cell_type":"code","source":"# Dropping the Customer ID column\nraw_data.drop('customerID', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.429324Z","iopub.execute_input":"2021-09-14T01:28:39.42981Z","iopub.status.idle":"2021-09-14T01:28:39.438395Z","shell.execute_reply.started":"2021-09-14T01:28:39.429778Z","shell.execute_reply":"2021-09-14T01:28:39.437454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unique values of each column\nfor column in raw_data.columns:\n    print(column)\n    print(raw_data[column].unique())\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.44036Z","iopub.execute_input":"2021-09-14T01:28:39.440973Z","iopub.status.idle":"2021-09-14T01:28:39.473563Z","shell.execute_reply.started":"2021-09-14T01:28:39.440934Z","shell.execute_reply":"2021-09-14T01:28:39.472455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data types\nraw_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.474958Z","iopub.execute_input":"2021-09-14T01:28:39.475322Z","iopub.status.idle":"2021-09-14T01:28:39.483597Z","shell.execute_reply.started":"2021-09-14T01:28:39.47529Z","shell.execute_reply":"2021-09-14T01:28:39.4825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## About the dtypes:\n\nMost of the dtypes are correct, but TotalCharges had to be a float64 instead of an object. Let's try to cast it.","metadata":{}},{"cell_type":"code","source":"# Converting the TotalCharges column\n#raw_data['TotalCharges'] = pd.to_numeric(raw_data['TotalCharges'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.485293Z","iopub.execute_input":"2021-09-14T01:28:39.485706Z","iopub.status.idle":"2021-09-14T01:28:39.494091Z","shell.execute_reply.started":"2021-09-14T01:28:39.485663Z","shell.execute_reply":"2021-09-14T01:28:39.493037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some blank values in the TotalCharges column, preventing us from converting the column to numeric. Let's investigate why.","metadata":{}},{"cell_type":"code","source":"# Locating the rows with blank values for TotalCharges\nraw_data.loc[raw_data['TotalCharges'] == ' ']","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.495529Z","iopub.execute_input":"2021-09-14T01:28:39.49591Z","iopub.status.idle":"2021-09-14T01:28:39.536955Z","shell.execute_reply.started":"2021-09-14T01:28:39.49588Z","shell.execute_reply":"2021-09-14T01:28:39.535885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The reason for those blank values is that those clients have just signed up for the services, as we can see in the tenure column (0). So we can assign these blank values to 0, because they haven't been charged yet.","metadata":{}},{"cell_type":"code","source":"# Assigning 0 to the blank values \nraw_data.loc[(raw_data['TotalCharges'] == ' '), 'TotalCharges'] = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.539818Z","iopub.execute_input":"2021-09-14T01:28:39.540136Z","iopub.status.idle":"2021-09-14T01:28:39.547251Z","shell.execute_reply.started":"2021-09-14T01:28:39.540106Z","shell.execute_reply":"2021-09-14T01:28:39.546274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we can convert the column to a numeric dtype\nraw_data['TotalCharges'] = pd.to_numeric(raw_data['TotalCharges'])\nraw_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.549327Z","iopub.execute_input":"2021-09-14T01:28:39.549636Z","iopub.status.idle":"2021-09-14T01:28:39.568589Z","shell.execute_reply.started":"2021-09-14T01:28:39.549608Z","shell.execute_reply":"2021-09-14T01:28:39.567407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mapping\n\nOne last thing: just for the sake of the example, let's map the values of the columns so that they are just like in the seminar.","metadata":{}},{"cell_type":"code","source":"raw_data['SeniorCitizen'] = raw_data['SeniorCitizen'].map({0: 'No', 1: 'Yes'})\nraw_data['Churn'] = raw_data['Churn'].map({'No': 0, 'Yes': 1})","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.570004Z","iopub.execute_input":"2021-09-14T01:28:39.570433Z","iopub.status.idle":"2021-09-14T01:28:39.580217Z","shell.execute_reply.started":"2021-09-14T01:28:39.570399Z","shell.execute_reply":"2021-09-14T01:28:39.579252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building\n\nIn this section we will:\n\n* Separate the inputs and targets (independent and dependent variables)\n* Split training and testing sets\n* Build our XGBoost model\n* Use GridSearchCV for parameter tuning","metadata":{}},{"cell_type":"code","source":"# Splitting inputs and targets\nX = raw_data.drop('Churn', axis=1).copy()\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.581433Z","iopub.execute_input":"2021-09-14T01:28:39.581833Z","iopub.status.idle":"2021-09-14T01:28:39.625109Z","shell.execute_reply.started":"2021-09-14T01:28:39.581789Z","shell.execute_reply":"2021-09-14T01:28:39.624117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = raw_data['Churn'].copy()\ny.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.627127Z","iopub.execute_input":"2021-09-14T01:28:39.62743Z","iopub.status.idle":"2021-09-14T01:28:39.634074Z","shell.execute_reply.started":"2021-09-14T01:28:39.627401Z","shell.execute_reply":"2021-09-14T01:28:39.63323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the unique values of y\ny.unique()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.635047Z","iopub.execute_input":"2021-09-14T01:28:39.635467Z","iopub.status.idle":"2021-09-14T01:28:39.64698Z","shell.execute_reply.started":"2021-09-14T01:28:39.635437Z","shell.execute_reply":"2021-09-14T01:28:39.646026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encoding\n\nWe will use one-hot encoding for the categorical columns.","metadata":{}},{"cell_type":"code","source":"# One-hot encoding\nX_encoded = pd.get_dummies(X, columns=['gender',\n                                       'SeniorCitizen',\n                                       'Partner',\n                                       'Dependents', \n                                       'PhoneService',\n                                       'MultipleLines',\n                                       'InternetService',\n                                       'OnlineSecurity',\n                                       'OnlineBackup',\n                                       'DeviceProtection',\n                                       'TechSupport',\n                                       'StreamingTV',\n                                       'StreamingMovies',\n                                       'Contract',\n                                       'PaperlessBilling',\n                                       'PaymentMethod'\n                                      ])\nX_encoded.head()\n\n#gender               object\n#SeniorCitizen         int64\n#Partner              object\n#Dependents           object\n#tenure                int64\n#PhoneService         object\n#MultipleLines        object\n#InternetService      object\n#OnlineSecurity       object\n#OnlineBackup         object\n#DeviceProtection     object\n#TechSupport          object\n#StreamingTV          object\n#StreamingMovies      object\n#Contract             object\n#PaperlessBilling     object\n#PaymentMethod        object\n#MonthlyCharges      float64\n#TotalCharges        float64","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.648174Z","iopub.execute_input":"2021-09-14T01:28:39.648484Z","iopub.status.idle":"2021-09-14T01:28:39.70855Z","shell.execute_reply.started":"2021-09-14T01:28:39.648456Z","shell.execute_reply":"2021-09-14T01:28:39.707521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost model\n\nFirst of all, let's observe that this data is imbalanced by diving the number of people who left the company by the total number of people in the dataset","metadata":{}},{"cell_type":"code","source":"sum(y)/len(y)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.709926Z","iopub.execute_input":"2021-09-14T01:28:39.710508Z","iopub.status.idle":"2021-09-14T01:28:39.719362Z","shell.execute_reply.started":"2021-09-14T01:28:39.710462Z","shell.execute_reply":"2021-09-14T01:28:39.718375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only 27% that left the company. Because of this, we will split the data into training and testing using stratification in order to maintain the same percentage of people that left in both sets.","metadata":{}},{"cell_type":"code","source":"# Splitting the data into training and testing using stratification\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.720779Z","iopub.execute_input":"2021-09-14T01:28:39.721076Z","iopub.status.idle":"2021-09-14T01:28:39.740154Z","shell.execute_reply.started":"2021-09-14T01:28:39.721046Z","shell.execute_reply":"2021-09-14T01:28:39.739412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's verify that using stratify worked as expected\nprint(sum(y_train)/len(y_train))\nprint(sum(y_test)/len(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.741089Z","iopub.execute_input":"2021-09-14T01:28:39.741483Z","iopub.status.idle":"2021-09-14T01:28:39.747369Z","shell.execute_reply.started":"2021-09-14T01:28:39.741453Z","shell.execute_reply":"2021-09-14T01:28:39.746506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's build the preliminary model. Instead of determining the optimal number of trees with cross validation, we will use early stopping to stop building trees when they no longer improve the situation.","metadata":{}},{"cell_type":"code","source":"# XGBoost\nclf_xgb = xgb.XGBClassifier(objective='binary:logistic', seed=42)\nclf_xgb.fit(X_train,\n            y_train,\n            verbose=True,\n            early_stopping_rounds=10,\n            eval_metric='aucpr',\n            eval_set=[(X_test, y_test)])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:39.748743Z","iopub.execute_input":"2021-09-14T01:28:39.749043Z","iopub.status.idle":"2021-09-14T01:28:40.141286Z","shell.execute_reply.started":"2021-09-14T01:28:39.749015Z","shell.execute_reply":"2021-09-14T01:28:40.140373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(clf_xgb, \n                      X_test, \n                      y_test, \n                      values_format='d', \n                      display_labels=[\"Did not leave\", \"Left\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:40.142548Z","iopub.execute_input":"2021-09-14T01:28:40.142857Z","iopub.status.idle":"2021-09-14T01:28:40.383713Z","shell.execute_reply.started":"2021-09-14T01:28:40.142825Z","shell.execute_reply":"2021-09-14T01:28:40.382722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameter tuning with GridSearchCV\n\nLet's try to improve the churn prediction using GridSearchCV","metadata":{}},{"cell_type":"code","source":"# GridSearchCV\n# param_grid = {\n#     'max_depth': [3, 4, 5],\n#     'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n#     'gamma': [0, 0.25, 1.0],\n#     'reg_lambda': [0, 1.0, 10.0],\n#     'scale_pos_weight': [1, 3, 5]\n# }\n\n# param_grid = {\n#     'max_depth': [1, 2, 3],\n#     'learning_rate': [0.07, 0.075, 0.08],\n#     'gamma': [0.9, 1.0, 1.1],\n#     'reg_lambda': [9.0, 10.0, 11.0],\n#     'scale_pos_weight': [3]\n# }\n\n# optimal_params = GridSearchCV(\n#     estimator=xgb.XGBClassifier(objective='binary:logistic', seed=42, subsample=0.9, colsample_bytree=0.5),\n#     param_grid=param_grid,\n#     scoring='roc_auc',\n#     verbose=2,\n#     n_jobs=10,\n#     cv=3\n# )\n\n# optimal_params.fit(X_train,\n#                    y_train,\n#                    early_stopping_rounds=10,\n#                    eval_metric='auc',\n#                    eval_set=[(X_test, y_test)],\n#                    verbose=False)\n\n# print(optimal_params.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:28:40.385009Z","iopub.execute_input":"2021-09-14T01:28:40.385347Z","iopub.status.idle":"2021-09-14T01:29:28.097643Z","shell.execute_reply.started":"2021-09-14T01:28:40.385314Z","shell.execute_reply":"2021-09-14T01:29:28.095455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I ran it on my PC because it was taking too long here, and the output was:\n\n> {'gamma': 1.0, 'learning_rate': 0.07, 'max_depth': 3, 'reg_lambda': 10.0, 'scale_pos_weight': 3}\n\nSo let's see how much improvment we can make with those parameters","metadata":{}},{"cell_type":"code","source":"# XGBoost\nclf_xgb = xgb.XGBClassifier(\n    seed=42,\n    objective='binary:logistic',\n    gamma=1.0,\n    learn_rate=0.07,\n    max_depth=3,\n    reg_lambda=10,\n    scale_pos_weight=3,\n    subsample=0.9,\n    colsample_bytree=0.5\n)\n\nclf_xgb.fit(\n    X_train,\n    y_train,\n    verbose=True,\n    early_stopping_rounds=10,\n    eval_metric='aucpr',\n    eval_set=[(X_test, y_test)]\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:29:35.741091Z","iopub.execute_input":"2021-09-14T01:29:35.741584Z","iopub.status.idle":"2021-09-14T01:29:37.295456Z","shell.execute_reply.started":"2021-09-14T01:29:35.741535Z","shell.execute_reply":"2021-09-14T01:29:37.294321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(clf_xgb, \n                      X_test, \n                      y_test, \n                      values_format='d', \n                      display_labels=[\"Did not leave\", \"Left\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:29:40.22703Z","iopub.execute_input":"2021-09-14T01:29:40.227395Z","iopub.status.idle":"2021-09-14T01:29:40.447096Z","shell.execute_reply.started":"2021-09-14T01:29:40.227364Z","shell.execute_reply":"2021-09-14T01:29:40.446432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results\n\nAfter using GridSearchCV for tuning our parameters we improved our churn prediction from *51,8%* (242 out of 467) to *82,6%* (386 out of 467)","metadata":{}}]}