{"cells":[{"metadata":{},"cell_type":"markdown","source":"**In this notebook I'm testing for the first time XGBoost library, by applying it on the Boston Housing dataset, on which I'll predict the house prices considering 14 features of the houses in the database.\nFirstly, I'm testing the model without tuning any parameter, and then I'll take the parameters one by one and try to improve the model's mean square error.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing libraries here:","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nfrom xgboost import XGBRegressor\nfrom sklearn.datasets import load_boston\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load dataset\nhouse_price = load_boston()\ndf_labels = pd.DataFrame(house_price.target)\ndf = pd.DataFrame(house_price.data)\nprint(df_labels.head())\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The database is splitted in two:  1. the target variable, the price - df_labels, and 2. the rest of the independent variables, df.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now giving the price column its rightful name:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_labels.columns = ['PRICE']\ndf.columns = house_price.feature_names\nprint(df_labels.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And putting them together to have a full database:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = df.merge(df_labels, left_index = True, right_index = True)\ndf_total.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's standardize the data and make the train/test split:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = preprocessing.scale(df)\nX_train, X_test, y_train, y_test = train_test_split(\n    df, df_labels, test_size=0.3, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now starts the XGBoost part, with the first test, non-tuned:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost part here!\n\nmy_model = XGBRegressor()\nmy_model.fit(X_train, y_train, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's have a look at the MSE on the train database:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nrmse ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I get a 0.012 MSE, ok, quite impressively and not necessarily good low value, so let's see how it performs on the test set:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nrmse ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Got a 3.431 MSE (for comparison, using a non-tuned Linear Regression I got 5.41 so  XGBoost - even non-tuned, seems better that Linear Regression).\n\nNow, let's start tuning the first parameter:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. n_estimators","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#n_estimators usually varies between 100 and 1000 so let's try it:\n\nmy_model = XGBRegressor(n_estimators = 100)\nmy_model.fit(X_train, y_train, verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, getting the same MSE tells us that in fact n_estimators is by default 100. \nLet's try with more options:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#n_estimators 2nd option, 200:\n\nmy_model = XGBRegressor(n_estimators = 200)\nmy_model.fit(X_train, y_train, verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The MSE improved, on both datasets, even if on the test one the difference is small.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#n_estimators 3rd option, 500:\n\nmy_model = XGBRegressor(n_estimators = 500)\nmy_model.fit(X_train, y_train, verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not a significant difference, so I'll test the highest value:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#n_estimators 4th option, 1000:\n\nmy_model = XGBRegressor(n_estimators = 1000)\nmy_model.fit(X_train, y_train, verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll stop the tests on this and try to have a look at the next parameter:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"2. early_stopping_rounds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# starting with a minimum of 5 early stopping rounds:\nmy_model = XGBRegressor(n_estimators = 1000)\nmy_model.fit(X_train, y_train,early_stopping_rounds=5,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The MSE is not better than when we didn't set this parameter, so let's try with another value for it:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# continuing with 15 early stopping rounds:\nmy_model = XGBRegressor(n_estimators = 1000)\nmy_model.fit(X_train, y_train,early_stopping_rounds=15,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.4303 MSE, slightly better.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# continuing with 15 early stopping rounds:\nmy_model = XGBRegressor(n_estimators = 1000)\nmy_model.fit(X_train, y_train,early_stopping_rounds=50,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# continuing with ( too much) 100 early stopping rounds:\nmy_model = XGBRegressor(n_estimators = 1000)\nmy_model.fit(X_train, y_train,early_stopping_rounds=100,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll stop here with the early stopping rounds parameter and move on to the next one:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"3. learning_rate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# starting with a small learning rate:\nmy_model = XGBRegressor(n_estimators = 1000,learning_rate=0.05)\nmy_model.fit(X_train, y_train,early_stopping_rounds=100,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Smallest MSE until now, 3.42; let's increase the learning rate:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# increasing the learning rate:\nmy_model = XGBRegressor(n_estimators = 1000,learning_rate=0.1)\nmy_model.fit(X_train, y_train,early_stopping_rounds=100,eval_set=[(X_test, y_test)], verbose=False)\n\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MSE even lower, nice, should I try even more?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = XGBRegressor(n_estimators = 1000,learning_rate=0.15)\nmy_model.fit(X_train, y_train,early_stopping_rounds=100,eval_set=[(X_test, y_test)], verbose=False)\n#early_stopping_rounds can very well be kept at a much lower value, as it doesn't make a big difference\n#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = my_model.predict(X_train)\nmse = mean_squared_error(y_train_predicted, y_train)\nrmse = np.sqrt(mse)\nprint(rmse)\n\n#on test set\ny_test_predicted = my_model.predict(X_test)\nmse = mean_squared_error(y_test_predicted, y_test)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No. It's already starting to increase again.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**For a variable that looks as follows, the best option when tuning XGBoost parameters was one that produced a MSE of 3.37 on the test set; this isn't, by no means, the perfect solution. The next step is to automatize this testing part so I could get a better match for the three parameters I worked on.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_labels.describe()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}