{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nimport os\n\n#print(os.listdir(\"../input/us-census-data\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/us-census-data/adult-training.csv\")\ndf_test = pd.read_csv(\"../input/us-census-data/adult-test.csv\")\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns=[\"age\", \"workclass\", \"fnlwgt\",\"education\", \"education-num\",\"marital_status\",\n                  \"occupation\",\"relationship\",\"race\", \"gender\",\"capital_gain\",\"capital_loss\",\n                  \"hours_per_week\",\"native_country\",\"income\"]\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#只有int和float数据\ndf_train.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 数据预处理\n### 转为类别数据\n将object数据转为类别数据，Ordinal Encoding to Categoricals"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df_train.columns:\n    if df_train[feature].dtype == 'object':\n        df_train[feature] = pd.Categorical(df_train[feature]).codes\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 数据标准化\nStandard Scalar"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nX_df = df_train.drop(df_train.columns[-1],1)\ny_df = df_train.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X_df)\ny = np.array(y_df)\n\nscaler = StandardScaler()\nX =scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection(特征选取)\n- Use Decision TreeClassifier to choose the feature\n- choose 10 feature(total 15 columns,last column is label)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X,y)\n\nrelval = tree.feature_importances_\n\nlr = DecisionTreeClassifier()\nnames = X_df.columns.tolist()\n\nselector = RFE(lr, n_features_to_select=10)\nselector.fit(X, y.ravel())\n\nprint(\"feature after order: \", sorted(zip(map(lambda x:round(x,4), selector.ranking_), names)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_new = X_df.iloc[:,selector.get_support(indices = False)]\nX_df_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 切分数据集和测试集\nX_new = scaler.fit_transform(np.array(X_df_new.astype(float)))\nX_train, X_test, y_train, y_test = train_test_split(X_new,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 建立Logistic Regression模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nlr = LogisticRegression()\nlr_clf = lr.fit(X_train, y_train.ravel())\ny_pred = lr_clf.predict(X_test)\n\nprint(\"Logistic Regression %s\" % metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## 建立XGBoost模型\n\n\n- brute force scan for all parameters, here are the tricks\n- usually max_depth is 6,7,8\n- learning rate is around 0.05, but small changes may make big diff\n- tuning min_child_weight subsample colsample_bytree can have much fun of fighting against overfit \n- n_estimators is how many round of boosting\n- ensemble xgboost with multiple seeds may reduce variance\n\n- learning rate:通过减少每一步的权重，可以提高模型的鲁棒性\n- colsample_bytree,用来控制每棵随机采样的列数的占比(每一列是一个特征)\n- max_depth,max_depth越大，模型会学到更具体更局部的样本\n- min_child_weight 决定最小叶子节点样本权重和\n- subsample 这个参数控制对于每棵树，随机采样的比例,一般0.5-1\n- objective 目标函数的选择要根据问题确定，如果是回归问题 ，一般是 reg:linear , reg:logistic , count:poisson 如果是分类问题，一般是binary:logistic ,rank:pairwise\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n\n### GridSearchCV(栅格搜索交叉验证）\n调用sklearn.model_selection的GridSearchCV进行模型调参\n- 需要传入4个参数\n- 第1个参数是模型对象，\n- 第2个参数是参数表格，数据类型为字典，\n- 第3个关键字参数cv的数据类型是交叉验证对象，\n- 第4个关键字参数scoring是字符串str或评分函数对象"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std = scaler.fit_transform(X_train)\nX_test_std = scaler.fit_transform(X_test)\n\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n# 1. 调整max_depth和min_child-weight，步长为2\ncv_params = {'max_depth': [3, 5, 7,9], 'min_child-weight': [1, 3, 5]}\n\nind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'send':0, \n             'subsample': 0.8, 'colsample_bytree':0.8, 'objective': 'binary:logistic'}\n\nxgbm_gsearch1 = GridSearchCV(estimator = XGBClassifier(ind_params), param_grid = cv_params,\n                              cv = 5, scoring = 'accuracy', n_jobs = -1)\n\nxgb_optimized_clf = xgbm_gsearch1.fit(X_train_std, y_train.ravel())\n\nprint('the best parameters: ', xgb_optimized_clf.best_params_)\n\nmeans = xgb_optimized_clf.cv_results_['mean_test_score']\nstds = xgb_optimized_clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, xgb_optimized_clf.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n          % (mean, std * 2, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 看出最佳组合为:  {'max_depth': 7, 'min_child-weight': 1}\n# 调整max_depth和min_child-weight，步长为1\n\ncv_params = {'max_depth': [5, 6, 7], 'min_child-weight': [1, 2, 3]}\n\nind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'send':0, \n             'subsample': 0.8, 'colsample_bytree':0.8, 'objective': 'binary:logistic'}\n\nxgbm_gsearch1 = GridSearchCV(estimator = XGBClassifier(ind_params), param_grid = cv_params,\n                              cv = 5, scoring = 'accuracy', n_jobs = -1)\n\nxgb_optimized_clf = xgbm_gsearch1.fit(X_train_std, y_train.ravel())\n\nprint('the best parameters: ', xgb_optimized_clf.best_params_)\n\nmeans = xgb_optimized_clf.cv_results_['mean_test_score']\nstds = xgb_optimized_clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, xgb_optimized_clf.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n          % (mean, std * 2, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 预测测试集数据\ny_pred = xgb_optimized_clf.predict(X_test_std)\n\n\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- sklearn.metrics的classification_report函数用于显示主要分类指标的文本报告．在报告中显示每个类的准确率，召回率，F1值等信息,support列为每个标签的出现次数\n- 可以看出，这次参数的准确率为85%，召回率为86%\n- 根据得出的最佳参数为'max_depth': 7, 'min_child-weight': 1，继续修改参数\n\n### 调XGBoost参数"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 调整 learning rate和subsample\ncv_params_new = {'learning rate':[0.1, 0.05, 0.01], 'subsample': [i/100 for i in range(75, 90, 5)]}\n\nxgbm_gsearch2 = GridSearchCV(estimator = XGBClassifier(max_depth=7, min_child_weight=1, n_estimators=1000, seed=0, \n                            colsample_bytree=0.8, objective='binary:logistic'),\n                             param_grid = cv_params_new, scoring='accuracy', cv=5, n_jobs=-1)\n\nxgb_optimized_clf = xgbm_gsearch2.fit(X_train_std, y_train.ravel())\n\nprint('the best parameters: ', xgb_optimized_clf.best_params_)\n\nmeans = xgb_optimized_clf.cv_results_['mean_test_score']\nstds = xgb_optimized_clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, xgb_optimized_clf.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n          % (mean, std * 2, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 预测测试集数据\ny_pred = xgb_optimized_clf.predict(X_test_std)\n\n\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 防止过拟合\n使用Early Stopping CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nxgb_matrix = xgb.DMatrix(X_train,y_train)\n\nparams_best = {'max-depth':7, 'min_child_weight':1, 'subsample':0.85, 'learning_rate':0.1, \n         'n_estimators':1000, 'seed':0, 'colsample_bytree':0.8, 'objective':'binary:logistic'}\n\ncv_xgb = xgb.cv(params = params_best, dtrain = xgb_matrix, num_boost_round = 3000,\n                nfold = 5, metrics=['error'], early_stopping_rounds = 100)\n\nprint(cv_xgb.tail(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_xgb_model = xgb.train(params=params_best, dtrain=xgb.DMatrix(X_train,y_train), num_boost_round=1000)\n\n## 在预测集上的结果\ntest_mat = xgb.DMatrix(X_test)\ny_pred = final_xgb_model.predict(test_mat)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#概率转为类别\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred <= 0.5] =0\n\nprint(\"XGBoost accuracy is {0:.2%}\".format(metrics.accuracy_score(y_test, y_pred)))\n\nfeature_importance_dict = final_xgb_model.get_fscore()\nfeature_importance_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# #修改dict的key值\n# feature_importance_dict.update({'age':feature_importance_dict.pop('f0')})\n# feature_importance_dict.update({'workclass':feature_importance_dict.pop('f1')})\n# feature_importance_dict.update({'fnlwgt':feature_importance_dict.pop('f2')})\n# feature_importance_dict.update({'education-num':feature_importance_dict.pop('f3')})\n# feature_importance_dict.update({'occupation':feature_importance_dict.pop('f4')})\n# feature_importance_dict.update({'relationship':feature_importance_dict.pop('f5')})\n# feature_importance_dict.update({'capital_gain':feature_importance_dict.pop('f6')})\n# feature_importance_dict.update({'capital_loss':feature_importance_dict.pop('f7')})\n# feature_importance_dict.update({'hours_per_week':feature_importance_dict.pop('f8')})\n# feature_importance_dict.update({'native_country':feature_importance_dict.pop('f9')})\n\n\n%matplotlib inline\nimport seaborn as sns\nsns.set(font_scale = 1.5)\n\nxgb.plot_importance(final_xgb_model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 显示预测结果\n### 分类报告"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看出准确率达到86%，召回率达到87%"},{"metadata":{},"cell_type":"markdown","source":"### 绘制混淆矩阵"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plt_confusion_matirx(cm, classes, title = \"Confusion Matrix\",cmap = plt.cm.Reds):\n    plt.imshow(cm, interpolation=\"nearest\", cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n    \n    thresh = cm.max()/2.0\n    for i , j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j ,i , cm[i, j], horizontalalignment=\"center\", \n                 color= \"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.xlabel(\"Predicted Classification\")\n    plt.ylabel(\"True Classification\")\n\ncm = confusion_matrix(y_test, y_pred)\nclass_names=[0, 1]\nplt.figure()\nplt_confusion_matirx(cm, classes=class_names, title=\"Confusion Matrix\",cmap = plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}